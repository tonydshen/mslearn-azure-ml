{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check azure-ai-ml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.29.0\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Connect to my workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1664965651163
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x000002A39BE19FD0>,\n",
              "         subscription_id=c6cdfd9c-3767-4be7-a343-0acd27ddefb9,\n",
              "         resource_group_name=rg-tshen-0917,\n",
              "         workspace_name=ml-ws-tshen-0917)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "#Enter    details    of    your    Azure    Machine    Learning    workspace\n",
        "subscription_id = 'c6cdfd9c-3767-4be7-a343-0acd27ddefb9'\n",
        "resource_group = 'rg-tshen-0917'\n",
        "workspace = 'ml-ws-tshen-0917'\n",
        "#connect to the workspace\n",
        "ml_client    =    MLClient(DefaultAzureCredential(),    subscription_id,\n",
        "resource_group,    workspace)\n",
        "ml_client"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1664965655212
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./src/train.py\n",
        "# train.py\n",
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# get parameters\n",
        "parser = argparse.ArgumentParser(\"train\")\n",
        "parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\n",
        "parser.add_argument(\"--n_estimators\", type=int, default=100, help=\"Number of trees in the forest\")\n",
        "parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
        "parser.add_argument(\"--test_size\", type=float, default=0.30, help=\"test size\")\n",
        "parser.add_argument(\"--random_state\", type=int, default=None, help=\"random state\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "print(args)\n",
        "\n",
        "training_data = args.training_data\n",
        "model_output = args.model_output\n",
        "n_estimators = args.n_estimators\n",
        "test_size = args.test_size\n",
        "random_state = args.random_state\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(training_data)  # Replace with your actual file\n",
        "\n",
        "# Assume the last column is the target\n",
        "# X = data.iloc[:, :-1]  # Features\n",
        "# y = data.iloc[:, -1]   # Target\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = (\n",
        "    df[\n",
        "        [\n",
        "            \"Pregnancies\",\n",
        "            \"PlasmaGlucose\",\n",
        "            \"DiastolicBloodPressure\",\n",
        "            \"TricepsThickness\",\n",
        "            \"SerumInsulin\",\n",
        "            \"BMI\",\n",
        "            \"DiabetesPedigree\",\n",
        "            \"Age\",\n",
        "        ]\n",
        "    ].values,\n",
        "    df[\"Diabetic\"].values,\n",
        ")\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=random_state\n",
        ")\n",
        "\n",
        "# Initialize and train the classifier\n",
        "model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(training_data='./diabetes-data/diabetes.csv', n_estimators=100, model_output='./model/random-forest.save', test_size=0.3, random_state=None)\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94      1990\n",
            "           1       0.89      0.89      0.89      1010\n",
            "\n",
            "    accuracy                           0.93      3000\n",
            "   macro avg       0.92      0.92      0.92      3000\n",
            "weighted avg       0.93      0.93      0.93      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python ./src/train.py --training_data ./diabetes-data/diabetes.csv --model_output ./model/random-forest.save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write pytorch_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/pytorch_iris.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./src/pytorch_iris.py\n",
        "# pytorch_iris.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# get parameters\n",
        "parser = argparse.ArgumentParser(\"train\")\n",
        "parser.add_argument(\"--training_data\", type=str, default='./iris-data/iris.csv', help=\"Path to training data\")\n",
        "parser.add_argument(\"--reg_rate\", type=float, default=0.01)\n",
        "parser.add_argument(\"--model_output\", type=str, default='./model/iris.save', help=\"Path of output model\")\n",
        "parser.add_argument(\"--test_size\", type=float, default=0.30, help=\"test size\")\n",
        "parser.add_argument(\"--random_state\", type=int, default=0, help=\"random state\")\n",
        "parser.add_argument(\"--n_epoch\", type=int, default=50, help=\"number of epochs\")\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=0.01, help=\"learning rate\")\n",
        "args = parser.parse_args()\n",
        "print(args)\n",
        "\n",
        "training_data = args.training_data\n",
        "reg_rate = args.reg_rate\n",
        "model_output = args.model_output\n",
        "test_size = args.test_size\n",
        "random_state = args.random_state\n",
        "n_epoch = args.n_epoch\n",
        "learning_rate = args.learning_rate\n",
        "\n",
        "# Load Iris dataset\n",
        "df = pd.read_csv(training_data)  # Replace with your actual file\n",
        "X = df.drop(\"species\", axis=1).values\n",
        "y = LabelEncoder().fit_transform(df[\"species\"])\n",
        "# Assume the last column is the target\n",
        "# X = df.iloc[:, :-1]  # Features\n",
        "# y = df.iloc[:, -1]   # Target\n",
        "\n",
        "# Preprocess\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Define model\n",
        "class IrisClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(4, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = IrisClassifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Save model\n",
        "# torch.save(model.state_dict(), \"iris_model.pt\")\n",
        "torch.save(model.state_dict(), model_output)\n",
        "\n",
        "# Evaluate\n",
        "with torch.no_grad():\n",
        "    preds = torch.argmax(model(X_test), dim=1)\n",
        "    acc = (preds == y_test).float().mean()\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run pytorch_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(training_data='./iris-data/iris.csv', reg_rate=0.01, model_output='./model/iris.save', test_size=0.3, random_state=0, n_epoch=50, learning_rate=0.01)\n",
            "Epoch 1, Loss: 1.1613\n",
            "Epoch 2, Loss: 1.1084\n",
            "Epoch 3, Loss: 1.0578\n",
            "Epoch 4, Loss: 1.0091\n",
            "Epoch 5, Loss: 0.9624\n",
            "Epoch 6, Loss: 0.9177\n",
            "Epoch 7, Loss: 0.8750\n",
            "Epoch 8, Loss: 0.8342\n",
            "Epoch 9, Loss: 0.7952\n",
            "Epoch 10, Loss: 0.7584\n",
            "Epoch 11, Loss: 0.7237\n",
            "Epoch 12, Loss: 0.6909\n",
            "Epoch 13, Loss: 0.6599\n",
            "Epoch 14, Loss: 0.6309\n",
            "Epoch 15, Loss: 0.6037\n",
            "Epoch 16, Loss: 0.5780\n",
            "Epoch 17, Loss: 0.5540\n",
            "Epoch 18, Loss: 0.5313\n",
            "Epoch 19, Loss: 0.5101\n",
            "Epoch 20, Loss: 0.4905\n",
            "Epoch 21, Loss: 0.4720\n",
            "Epoch 22, Loss: 0.4547\n",
            "Epoch 23, Loss: 0.4387\n",
            "Epoch 24, Loss: 0.4239\n",
            "Epoch 25, Loss: 0.4103\n",
            "Epoch 26, Loss: 0.3975\n",
            "Epoch 27, Loss: 0.3855\n",
            "Epoch 28, Loss: 0.3743\n",
            "Epoch 29, Loss: 0.3636\n",
            "Epoch 30, Loss: 0.3536\n",
            "Epoch 31, Loss: 0.3440\n",
            "Epoch 32, Loss: 0.3347\n",
            "Epoch 33, Loss: 0.3259\n",
            "Epoch 34, Loss: 0.3177\n",
            "Epoch 35, Loss: 0.3099\n",
            "Epoch 36, Loss: 0.3025\n",
            "Epoch 37, Loss: 0.2956\n",
            "Epoch 38, Loss: 0.2890\n",
            "Epoch 39, Loss: 0.2827\n",
            "Epoch 40, Loss: 0.2766\n",
            "Epoch 41, Loss: 0.2707\n",
            "Epoch 42, Loss: 0.2652\n",
            "Epoch 43, Loss: 0.2598\n",
            "Epoch 44, Loss: 0.2545\n",
            "Epoch 45, Loss: 0.2494\n",
            "Epoch 46, Loss: 0.2443\n",
            "Epoch 47, Loss: 0.2393\n",
            "Epoch 48, Loss: 0.2344\n",
            "Epoch 49, Loss: 0.2295\n",
            "Epoch 50, Loss: 0.2246\n",
            "Test Accuracy: 0.9333\n"
          ]
        }
      ],
      "source": [
        "!python ./src/pytorch_iris.py --training_data ./iris-data/iris.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write tensorflow_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/tensorflow_iris.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./src/tensorflow_iris.py\n",
        "# tensorflow_iris.py\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# get parameters\n",
        "parser = argparse.ArgumentParser(\"train\")\n",
        "parser.add_argument(\"--training_data\", type=str, default='./iris-data/iris.csv', help=\"Path to training data\")\n",
        "parser.add_argument(\"--reg_rate\", type=float, default=0.01)\n",
        "parser.add_argument(\"--model_output\", type=str, default='./model/iris_tf.keras', help=\"Path of output model, file extension .keras instead of .h5 required\")\n",
        "parser.add_argument(\"--test_size\", type=float, default=0.30, help=\"test size\")\n",
        "parser.add_argument(\"--random_state\", type=int, default=0, help=\"random state\")\n",
        "parser.add_argument(\"--n_epoch\", type=int, default=50, help=\"number of epochs\")\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=0.01, help=\"learning rate\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16, help=\"batch size\")\n",
        "parser.add_argument(\"--gpu\", type=str, default=\"no\", help=\"if gpu available yes/no\")\n",
        "args = parser.parse_args()\n",
        "print(args)\n",
        "\n",
        "training_data = args.training_data\n",
        "reg_rate = args.reg_rate\n",
        "model_output = args.model_output\n",
        "test_size = args.test_size\n",
        "random_state = args.random_state\n",
        "n_epoch = args.n_epoch\n",
        "learning_rate = args.learning_rate\n",
        "batch_size = args.batch_size\n",
        "gpu = args.gpu\n",
        "print(f\"GPU enabled: {gpu}\")\n",
        "\n",
        "# Load Iris dataset\n",
        "df = pd.read_csv(training_data)  # Replace with your actual file\n",
        "X = df.drop(\"species\", axis=1).values\n",
        "y = LabelEncoder().fit_transform(df[\"species\"])\n",
        "\n",
        "# Preprocess\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(batch_size, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# Train with GPU if available\n",
        "if gpu.lower() == \"yes\":    \n",
        "    print(\"Training with GPU...\")\n",
        "    with tf.device('/GPU:0'):\n",
        "        model.fit(X_train, y_train, epochs=n_epoch, batch_size=batch_size, verbose=1)\n",
        "else:\n",
        "    print(\"Training with CPU...\")   \n",
        "    model.fit(X_train, y_train, epochs=n_epoch, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Save model\n",
        "model.save(model_output) # Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run tensorflow_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-20 18:09:15.107229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(training_data='./iris-data/iris.csv', reg_rate=0.01, model_output='./model/iris_tf.keras', test_size=0.3, random_state=0, n_epoch=80, learning_rate=0.01, batch_size=16, gpu='yes')\n",
            "GPU enabled: yes\n",
            "/home/tshen/dp-100/mslearn-azure-ml/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758409759.944554   47390 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9556 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
            "Training with GPU...\n",
            "Epoch 1/80\n",
            "2025-09-20 18:09:22.127186: I external/local_xla/xla/service/service.cc:163] XLA service 0x7fea98004ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-09-20 18:09:22.127268: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
            "2025-09-20 18:09:22.148851: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-09-20 18:09:22.277411: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
            "I0000 00:00:1758409763.219048   47444 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.4667 - loss: 1.0070\n",
            "Epoch 2/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5905 - loss: 0.9600 \n",
            "Epoch 3/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6476 - loss: 0.9177\n",
            "Epoch 4/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6476 - loss: 0.8784 \n",
            "Epoch 5/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 0.8416 \n",
            "Epoch 6/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6667 - loss: 0.8077\n",
            "Epoch 7/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6952 - loss: 0.7755 \n",
            "Epoch 8/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7048 - loss: 0.7472 \n",
            "Epoch 9/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7143 - loss: 0.7180 \n",
            "Epoch 10/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7143 - loss: 0.6927 \n",
            "Epoch 11/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7238 - loss: 0.6693\n",
            "Epoch 12/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7619 - loss: 0.6467 \n",
            "Epoch 13/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7619 - loss: 0.6258 \n",
            "Epoch 14/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7619 - loss: 0.6070\n",
            "Epoch 15/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7619 - loss: 0.5888\n",
            "Epoch 16/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7810 - loss: 0.5720 \n",
            "Epoch 17/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8000 - loss: 0.5564 \n",
            "Epoch 18/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8000 - loss: 0.5421 \n",
            "Epoch 19/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8095 - loss: 0.5283 \n",
            "Epoch 20/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8286 - loss: 0.5156\n",
            "Epoch 21/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8381 - loss: 0.5035 \n",
            "Epoch 22/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8381 - loss: 0.4922\n",
            "Epoch 23/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8381 - loss: 0.4814\n",
            "Epoch 24/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8476 - loss: 0.4713\n",
            "Epoch 25/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8476 - loss: 0.4618\n",
            "Epoch 26/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8571 - loss: 0.4526\n",
            "Epoch 27/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.4440\n",
            "Epoch 28/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.4360\n",
            "Epoch 29/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8667 - loss: 0.4281\n",
            "Epoch 30/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8667 - loss: 0.4205\n",
            "Epoch 31/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.4136 \n",
            "Epoch 32/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8667 - loss: 0.4065\n",
            "Epoch 33/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8667 - loss: 0.4001 \n",
            "Epoch 34/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3937\n",
            "Epoch 35/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8667 - loss: 0.3877 \n",
            "Epoch 36/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8667 - loss: 0.3820 \n",
            "Epoch 37/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3762\n",
            "Epoch 38/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3707\n",
            "Epoch 39/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8667 - loss: 0.3655\n",
            "Epoch 40/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8667 - loss: 0.3604\n",
            "Epoch 41/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8667 - loss: 0.3558\n",
            "Epoch 42/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8667 - loss: 0.3509\n",
            "Epoch 43/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8667 - loss: 0.3461\n",
            "Epoch 44/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3419\n",
            "Epoch 45/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3376\n",
            "Epoch 46/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8762 - loss: 0.3337\n",
            "Epoch 47/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8762 - loss: 0.3292\n",
            "Epoch 48/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8762 - loss: 0.3255\n",
            "Epoch 49/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8762 - loss: 0.3216 \n",
            "Epoch 50/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8857 - loss: 0.3181 \n",
            "Epoch 51/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8857 - loss: 0.3142 \n",
            "Epoch 52/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8857 - loss: 0.3108\n",
            "Epoch 53/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8857 - loss: 0.3074\n",
            "Epoch 54/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8857 - loss: 0.3039\n",
            "Epoch 55/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8857 - loss: 0.3006\n",
            "Epoch 56/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8857 - loss: 0.2972\n",
            "Epoch 57/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8952 - loss: 0.2942\n",
            "Epoch 58/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8952 - loss: 0.2911  \n",
            "Epoch 59/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8952 - loss: 0.2880\n",
            "Epoch 60/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8952 - loss: 0.2850 \n",
            "Epoch 61/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8952 - loss: 0.2820 \n",
            "Epoch 62/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8952 - loss: 0.2788 \n",
            "Epoch 63/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8952 - loss: 0.2757\n",
            "Epoch 64/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8952 - loss: 0.2725\n",
            "Epoch 65/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8952 - loss: 0.2692\n",
            "Epoch 66/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.2663\n",
            "Epoch 67/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8952 - loss: 0.2634\n",
            "Epoch 68/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8952 - loss: 0.2605 \n",
            "Epoch 69/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8952 - loss: 0.2575\n",
            "Epoch 70/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.2545\n",
            "Epoch 71/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8952 - loss: 0.2520\n",
            "Epoch 72/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9048 - loss: 0.2490\n",
            "Epoch 73/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9143 - loss: 0.2463\n",
            "Epoch 74/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9143 - loss: 0.2437\n",
            "Epoch 75/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9143 - loss: 0.2409\n",
            "Epoch 76/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9143 - loss: 0.2384\n",
            "Epoch 77/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9143 - loss: 0.2358\n",
            "Epoch 78/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9143 - loss: 0.2334\n",
            "Epoch 79/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9238 - loss: 0.2309\n",
            "Epoch 80/80\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9238 - loss: 0.2284\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - accuracy: 0.8889 - loss: 0.2788\n",
            "Test Accuracy: 0.8889\n"
          ]
        }
      ],
      "source": [
        "!python ./src/tensorflow_iris.py --training_data ./iris-data/iris.csv --gpu yes --n_epoch 80 --learning_rate 0.01 --batch_size 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify GPU access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-19 19:30:31.753348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices())"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
