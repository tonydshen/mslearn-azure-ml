{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check azure-ai-ml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.29.0\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Connect to my workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1664965651163
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x000002A39BE19FD0>,\n",
              "         subscription_id=c6cdfd9c-3767-4be7-a343-0acd27ddefb9,\n",
              "         resource_group_name=rg-tshen-0917,\n",
              "         workspace_name=ml-ws-tshen-0917)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "#Enter    details    of    your    Azure    Machine    Learning    workspace\n",
        "subscription_id = 'c6cdfd9c-3767-4be7-a343-0acd27ddefb9'\n",
        "resource_group = 'rg-tshen-0917'\n",
        "workspace = 'ml-ws-tshen-0917'\n",
        "#connect to the workspace\n",
        "ml_client    =    MLClient(DefaultAzureCredential(),    subscription_id,\n",
        "resource_group,    workspace)\n",
        "ml_client"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1664965655212
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./src/train.py\n",
        "# train.py\n",
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# get parameters\n",
        "parser = argparse.ArgumentParser(\"train\")\n",
        "parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\n",
        "parser.add_argument(\"--n_estimators\", type=int, default=100, help=\"Number of trees in the forest\")\n",
        "parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
        "parser.add_argument(\"--test_size\", type=float, default=0.30, help=\"test size\")\n",
        "parser.add_argument(\"--random_state\", type=int, default=None, help=\"random state\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "print(args)\n",
        "\n",
        "training_data = args.training_data\n",
        "model_output = args.model_output\n",
        "n_estimators = args.n_estimators\n",
        "test_size = args.test_size\n",
        "random_state = args.random_state\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(training_data)  # Replace with your actual file\n",
        "\n",
        "# Assume the last column is the target\n",
        "# X = data.iloc[:, :-1]  # Features\n",
        "# y = data.iloc[:, -1]   # Target\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = (\n",
        "    df[\n",
        "        [\n",
        "            \"Pregnancies\",\n",
        "            \"PlasmaGlucose\",\n",
        "            \"DiastolicBloodPressure\",\n",
        "            \"TricepsThickness\",\n",
        "            \"SerumInsulin\",\n",
        "            \"BMI\",\n",
        "            \"DiabetesPedigree\",\n",
        "            \"Age\",\n",
        "        ]\n",
        "    ].values,\n",
        "    df[\"Diabetic\"].values,\n",
        ")\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=random_state\n",
        ")\n",
        "\n",
        "# Initialize and train the classifier\n",
        "model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(training_data='./diabetes-data/diabetes.csv', n_estimators=100, model_output='./model/random-forest.save', test_size=0.3, random_state=None)\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94      1990\n",
            "           1       0.89      0.89      0.89      1010\n",
            "\n",
            "    accuracy                           0.93      3000\n",
            "   macro avg       0.92      0.92      0.92      3000\n",
            "weighted avg       0.93      0.93      0.93      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python ./src/train.py --training_data ./diabetes-data/diabetes.csv --model_output ./model/random-forest.save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write pytorch_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/pytorch_iris.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./src/pytorch_iris.py\n",
        "# pytorch_iris.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# get parameters\n",
        "parser = argparse.ArgumentParser(\"train\")\n",
        "parser.add_argument(\"--training_data\", type=str, default='./iris-data/iris.csv', help=\"Path to training data\")\n",
        "parser.add_argument(\"--reg_rate\", type=float, default=0.01)\n",
        "parser.add_argument(\"--model_output\", type=str, default='./model/iris.save', help=\"Path of output model\")\n",
        "parser.add_argument(\"--test_size\", type=float, default=0.30, help=\"test size\")\n",
        "parser.add_argument(\"--random_state\", type=int, default=0, help=\"random state\")\n",
        "parser.add_argument(\"--n_epoch\", type=int, default=50, help=\"number of epochs\")\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=0.01, help=\"learning rate\")\n",
        "args = parser.parse_args()\n",
        "print(args)\n",
        "\n",
        "training_data = args.training_data\n",
        "reg_rate = args.reg_rate\n",
        "model_output = args.model_output\n",
        "test_size = args.test_size\n",
        "random_state = args.random_state\n",
        "n_epoch = args.n_epoch\n",
        "learning_rate = args.learning_rate\n",
        "\n",
        "# Load Iris dataset\n",
        "df = pd.read_csv(training_data)  # Replace with your actual file\n",
        "X = df.drop(\"species\", axis=1).values\n",
        "y = LabelEncoder().fit_transform(df[\"species\"])\n",
        "# Assume the last column is the target\n",
        "# X = df.iloc[:, :-1]  # Features\n",
        "# y = df.iloc[:, -1]   # Target\n",
        "\n",
        "# Preprocess\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Define model\n",
        "class IrisClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(4, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = IrisClassifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Save model\n",
        "# torch.save(model.state_dict(), \"iris_model.pt\")\n",
        "torch.save(model.state_dict(), model_output)\n",
        "\n",
        "# Evaluate\n",
        "with torch.no_grad():\n",
        "    preds = torch.argmax(model(X_test), dim=1)\n",
        "    acc = (preds == y_test).float().mean()\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run pytorch_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(training_data='./iris-data/iris.csv', reg_rate=0.01, model_output='./model/iris.save', test_size=0.3, random_state=0, n_epoch=50, learning_rate=0.01)\n",
            "Epoch 1, Loss: 1.1613\n",
            "Epoch 2, Loss: 1.1084\n",
            "Epoch 3, Loss: 1.0578\n",
            "Epoch 4, Loss: 1.0091\n",
            "Epoch 5, Loss: 0.9624\n",
            "Epoch 6, Loss: 0.9177\n",
            "Epoch 7, Loss: 0.8750\n",
            "Epoch 8, Loss: 0.8342\n",
            "Epoch 9, Loss: 0.7952\n",
            "Epoch 10, Loss: 0.7584\n",
            "Epoch 11, Loss: 0.7237\n",
            "Epoch 12, Loss: 0.6909\n",
            "Epoch 13, Loss: 0.6599\n",
            "Epoch 14, Loss: 0.6309\n",
            "Epoch 15, Loss: 0.6037\n",
            "Epoch 16, Loss: 0.5780\n",
            "Epoch 17, Loss: 0.5540\n",
            "Epoch 18, Loss: 0.5313\n",
            "Epoch 19, Loss: 0.5101\n",
            "Epoch 20, Loss: 0.4905\n",
            "Epoch 21, Loss: 0.4720\n",
            "Epoch 22, Loss: 0.4547\n",
            "Epoch 23, Loss: 0.4387\n",
            "Epoch 24, Loss: 0.4239\n",
            "Epoch 25, Loss: 0.4103\n",
            "Epoch 26, Loss: 0.3975\n",
            "Epoch 27, Loss: 0.3855\n",
            "Epoch 28, Loss: 0.3743\n",
            "Epoch 29, Loss: 0.3636\n",
            "Epoch 30, Loss: 0.3536\n",
            "Epoch 31, Loss: 0.3440\n",
            "Epoch 32, Loss: 0.3347\n",
            "Epoch 33, Loss: 0.3259\n",
            "Epoch 34, Loss: 0.3177\n",
            "Epoch 35, Loss: 0.3099\n",
            "Epoch 36, Loss: 0.3025\n",
            "Epoch 37, Loss: 0.2956\n",
            "Epoch 38, Loss: 0.2890\n",
            "Epoch 39, Loss: 0.2827\n",
            "Epoch 40, Loss: 0.2766\n",
            "Epoch 41, Loss: 0.2707\n",
            "Epoch 42, Loss: 0.2652\n",
            "Epoch 43, Loss: 0.2598\n",
            "Epoch 44, Loss: 0.2545\n",
            "Epoch 45, Loss: 0.2494\n",
            "Epoch 46, Loss: 0.2443\n",
            "Epoch 47, Loss: 0.2393\n",
            "Epoch 48, Loss: 0.2344\n",
            "Epoch 49, Loss: 0.2295\n",
            "Epoch 50, Loss: 0.2246\n",
            "Test Accuracy: 0.9333\n"
          ]
        }
      ],
      "source": [
        "!python ./src/pytorch_iris.py --training_data ./iris-data/iris.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write tensorflow_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/tensorflow_iris.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./src/tensorflow_iris.py\n",
        "# tensorflow_iris.py\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# get parameters\n",
        "parser = argparse.ArgumentParser(\"train\")\n",
        "parser.add_argument(\"--training_data\", type=str, default='./iris-data/iris.csv', help=\"Path to training data\")\n",
        "parser.add_argument(\"--reg_rate\", type=float, default=0.01)\n",
        "parser.add_argument(\"--model_output\", type=str, default='./model/iris_tf.keras', help=\"Path of output model, file extension .keras instead of .h5 required\")\n",
        "parser.add_argument(\"--test_size\", type=float, default=0.30, help=\"test size\")\n",
        "parser.add_argument(\"--random_state\", type=int, default=0, help=\"random state\")\n",
        "parser.add_argument(\"--n_epoch\", type=int, default=50, help=\"number of epochs\")\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=0.01, help=\"learning rate\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16, help=\"batch size\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "print(args)\n",
        "\n",
        "training_data = args.training_data\n",
        "reg_rate = args.reg_rate\n",
        "model_output = args.model_output\n",
        "test_size = args.test_size\n",
        "random_state = args.random_state\n",
        "n_epoch = args.n_epoch\n",
        "learning_rate = args.learning_rate\n",
        "batch_size = args.batch_size\n",
        "\n",
        "# Load Iris dataset\n",
        "df = pd.read_csv(training_data)  # Replace with your actual file\n",
        "X = df.drop(\"species\", axis=1).values\n",
        "y = LabelEncoder().fit_transform(df[\"species\"])\n",
        "\n",
        "# Preprocess\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(batch_size, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train, epochs=n_epoch, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Save model\n",
        "model.save(model_output) # Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run tensorflow_iris.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(training_data='./iris-data/iris.csv', reg_rate=0.01, model_output='./model/iris_tf.keras', test_size=0.3, random_state=0, n_epoch=50, learning_rate=0.01, batch_size=16)\n",
            "Epoch 1/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 686ms/step - accuracy: 0.6250 - loss: 0.9791\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5905 - loss: 0.9451  \n",
            "Epoch 2/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.9396\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6190 - loss: 0.9047 \n",
            "Epoch 3/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6875 - loss: 0.8365\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6381 - loss: 0.8670 \n",
            "Epoch 4/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.7568\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.8324 \n",
            "Epoch 5/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6875 - loss: 0.8187\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7143 - loss: 0.7983 \n",
            "Epoch 6/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8125 - loss: 0.7625\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7143 - loss: 0.7671 \n",
            "Epoch 7/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6250 - loss: 0.7577\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7143 - loss: 0.7368 \n",
            "Epoch 8/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8750 - loss: 0.6173\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7429 - loss: 0.7107 \n",
            "Epoch 9/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.6705\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7524 - loss: 0.6837 \n",
            "Epoch 10/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 0.6495\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7619 - loss: 0.6598 \n",
            "Epoch 11/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6645\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.6368 \n",
            "Epoch 12/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.6127\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8000 - loss: 0.6156 \n",
            "Epoch 13/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6875 - loss: 0.7068\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 0.5954 \n",
            "Epoch 14/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8125 - loss: 0.5751\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.5763 \n",
            "Epoch 15/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.4678\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.5595 \n",
            "Epoch 16/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8125 - loss: 0.4907\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.5428 \n",
            "Epoch 17/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6875 - loss: 0.5778\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 0.5273 \n",
            "Epoch 18/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8125 - loss: 0.4313\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.5125 \n",
            "Epoch 19/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.5827\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.4987 \n",
            "Epoch 20/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9375 - loss: 0.4323\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.4863 \n",
            "Epoch 21/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6875 - loss: 0.5664\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - loss: 0.4737 \n",
            "Epoch 22/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.4471\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8571 - loss: 0.4628 \n",
            "Epoch 23/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.5340\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.4515 \n",
            "Epoch 24/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.3766\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8571 - loss: 0.4418 \n",
            "Epoch 25/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.4965\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.4318 \n",
            "Epoch 26/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8125 - loss: 0.3655\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8571 - loss: 0.4230 \n",
            "Epoch 27/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.4361\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8571 - loss: 0.4145 \n",
            "Epoch 28/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8750 - loss: 0.4084\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8571 - loss: 0.4060 \n",
            "Epoch 29/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.5819\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8571 - loss: 0.3983 \n",
            "Epoch 30/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8125 - loss: 0.4324\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8476 - loss: 0.3909 \n",
            "Epoch 31/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8750 - loss: 0.4242\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8571 - loss: 0.3841 \n",
            "Epoch 32/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8750 - loss: 0.4030\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3772 \n",
            "Epoch 33/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9375 - loss: 0.4092\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3708 \n",
            "Epoch 34/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8750 - loss: 0.3862\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3646 \n",
            "Epoch 35/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9375 - loss: 0.3111\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3586 \n",
            "Epoch 36/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8125 - loss: 0.4063\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3530 \n",
            "Epoch 37/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9375 - loss: 0.2877\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3475 \n",
            "Epoch 38/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9375 - loss: 0.2960\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.3420 \n",
            "Epoch 39/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 0.5331\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3374 \n",
            "Epoch 40/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.3678\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3322 \n",
            "Epoch 41/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8750 - loss: 0.3370\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3275 \n",
            "Epoch 42/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6250 - loss: 0.5427\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3224 \n",
            "Epoch 43/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8125 - loss: 0.3136\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3176 \n",
            "Epoch 44/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8750 - loss: 0.3480\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3133 \n",
            "Epoch 45/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.2763\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3089 \n",
            "Epoch 46/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.3413\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.3049 \n",
            "Epoch 47/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8125 - loss: 0.3717\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3007 \n",
            "Epoch 48/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.3046\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.2965 \n",
            "Epoch 49/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.2376\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.2928 \n",
            "Epoch 50/50\n",
            "\n",
            "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1838\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8762 - loss: 0.2890 \n",
            "\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7812 - loss: 0.3830\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8000 - loss: 0.3478 \n",
            "Test Accuracy: 0.8000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-19 10:46:39.660231: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "2025-09-19 10:46:43.957957: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "c:\\Users\\Tony\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025-09-19 10:46:48.012704: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "!python ./src/tensorflow_iris.py --training_data ./iris-data/iris.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify GPU access"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
